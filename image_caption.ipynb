{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2055259,
          "sourceType": "datasetVersion",
          "datasetId": 1231480
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "image_caption",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mani1881/imp_caption/blob/main/image_caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sakshighadigaonkar_flickr_8k_path = kagglehub.dataset_download('sakshighadigaonkar/flickr-8k')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "5DQfrZI6qrt2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K  # Updated to tf.keras\n",
        "import sys, time, os, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Optional: Configure TensorFlow to limit GPU memory usage (if you're using a GPU)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth set.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Print version information\n",
        "print(\"python {}\".format(sys.version))\n",
        "print(\"tensorflow version {}\".format(tf.__version__))\n",
        "print(\"keras version {}\".format(tf.keras.__version__))  # Keras is integrated into TensorFlow 2.x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:20:49.614337Z",
          "iopub.execute_input": "2024-10-27T12:20:49.615174Z",
          "iopub.status.idle": "2024-10-27T12:21:04.445936Z",
          "shell.execute_reply.started": "2024-10-27T12:20:49.61511Z",
          "shell.execute_reply": "2024-10-27T12:21:04.444744Z"
        },
        "trusted": true,
        "id": "ogX1rEbCqrt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuring the GPU memory to be used for training purposes\n",
        "# Set GPU memory usage (if a GPU is available)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Set each GPU to grow memory as needed, but it won't exceed available memory\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"Enabled memory growth for each GPU.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(sd=144):\n",
        "    # Numpy random seed\n",
        "    np.random.seed(sd)\n",
        "    # Python's core random number generator seed\n",
        "    rn.seed(sd)\n",
        "    # TensorFlow random seed\n",
        "    tf.random.set_seed(sd)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:21:21.466944Z",
          "iopub.execute_input": "2024-10-27T12:21:21.468005Z",
          "iopub.status.idle": "2024-10-27T12:21:21.475723Z",
          "shell.execute_reply.started": "2024-10-27T12:21:21.467954Z",
          "shell.execute_reply": "2024-10-27T12:21:21.474442Z"
        },
        "trusted": true,
        "id": "M0GxyqcHqrt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the image dataset and its respective captions\n",
        "import os\n",
        "\n",
        "# Define the paths to the images and caption file\n",
        "dir_Flickr_jpg = \"/kaggle/input/flickr-8k/Flickr8k_Dataset/Flicker8k_Dataset\"\n",
        "dir_Flickr_text = \"/kaggle/input/flickr-8k/Flickr8k_text/Flickr8k.token.txt\"\n",
        "\n",
        "# List jpg files in the directory and count them\n",
        "try:\n",
        "    jpgs = os.listdir(dir_Flickr_jpg)\n",
        "    print(\"The number of jpg files in Flicker8k: {}\".format(len(jpgs)))\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:21:43.657922Z",
          "iopub.execute_input": "2024-10-27T12:21:43.658939Z",
          "iopub.status.idle": "2024-10-27T12:21:44.297242Z",
          "shell.execute_reply.started": "2024-10-27T12:21:43.65889Z",
          "shell.execute_reply": "2024-10-27T12:21:44.296107Z"
        },
        "trusted": true,
        "id": "nIOWlI72qrt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the captions for each image.\n",
        "file = open(dir_Flickr_text,'r', encoding='utf8')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "\n",
        "datatxt = []\n",
        "for line in text.split('\\n'):\n",
        "    col = line.split('\\t')\n",
        "    if len(col) == 1:\n",
        "        continue\n",
        "    w = col[0].split(\"#\") # Splitting the caption dataset at the required position\n",
        "    datatxt.append(w + [col[1].lower()])\n",
        "\n",
        "df_txt = pd.DataFrame(datatxt,columns=[\"filename\",\"index\",\"caption\"])\n",
        "\n",
        "\n",
        "uni_filenames = np.unique(df_txt.filename.values)\n",
        "print(\"The number of unique file names : {}\".format(len(uni_filenames)))\n",
        "print(\"The distribution of the number of captions for each image:\")\n",
        "Counter(Counter(df_txt.filename.values).values())\n",
        "print(df_txt[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:22:14.369806Z",
          "iopub.execute_input": "2024-10-27T12:22:14.370786Z",
          "iopub.status.idle": "2024-10-27T12:22:14.78811Z",
          "shell.execute_reply.started": "2024-10-27T12:22:14.370743Z",
          "shell.execute_reply": "2024-10-27T12:22:14.786702Z"
        },
        "trusted": true,
        "id": "Oq9hzRA0qrt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting few images and their captions from the dataset\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "npic = 5 # Displaying 5 images from the dataset\n",
        "npix = 224\n",
        "target_size = (npix,npix,3)\n",
        "\n",
        "count = 1\n",
        "fig = plt.figure(figsize=(10,20))\n",
        "for jpgfnm in uni_filenames[-5:]:\n",
        "    filename = dir_Flickr_jpg + '/' + jpgfnm\n",
        "    captions = list(df_txt[\"caption\"].loc[df_txt[\"filename\"]==jpgfnm].values)\n",
        "    image_load = load_img(filename, target_size=target_size)\n",
        "\n",
        "    ax = fig.add_subplot(npic,2,count,xticks=[],yticks=[])\n",
        "    ax.imshow(image_load)\n",
        "    count += 1\n",
        "\n",
        "    ax = fig.add_subplot(npic,2,count)\n",
        "    plt.axis('off')\n",
        "    ax.plot()\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,len(captions))\n",
        "    for i, caption in enumerate(captions):\n",
        "        ax.text(0,i,caption,fontsize=20)\n",
        "    count += 1\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:22:45.798935Z",
          "iopub.execute_input": "2024-10-27T12:22:45.799426Z",
          "iopub.status.idle": "2024-10-27T12:22:46.939139Z",
          "shell.execute_reply.started": "2024-10-27T12:22:45.799382Z",
          "shell.execute_reply": "2024-10-27T12:22:46.93774Z"
        },
        "trusted": true,
        "id": "vK_wAtaeqrt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning captions for further analysis\n",
        "# Defining a function to calculate the top 3 words in all the captions available for the images\n",
        "def df_word(df_txt):\n",
        "    vocabulary = []\n",
        "    for txt in df_txt.caption.values:\n",
        "        vocabulary.extend(txt.split())\n",
        "    print('Vocabulary Size: %d' % len(set(vocabulary)))\n",
        "    ct = Counter(vocabulary)\n",
        "    dfword = pd.DataFrame({\"word\":list(ct.keys()),\"count\":list(ct.values())})\n",
        "    dfword = dfword.sort_values(\"count\",ascending=False)\n",
        "    dfword = dfword.reset_index()[[\"word\",\"count\"]]\n",
        "    return(dfword)\n",
        "dfword = df_word(df_txt)\n",
        "dfword.head(3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:23:16.952685Z",
          "iopub.execute_input": "2024-10-27T12:23:16.953104Z",
          "iopub.status.idle": "2024-10-27T12:23:17.134955Z",
          "shell.execute_reply.started": "2024-10-27T12:23:16.953066Z",
          "shell.execute_reply": "2024-10-27T12:23:17.133549Z"
        },
        "trusted": true,
        "id": "fsSy3cF2qrt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning the captions for further processing\n",
        "import string\n",
        "text_original = \"I ate 1000 apples and a banana. I have python v2.7. It's 2:30 pm. Could you buy me iphone7?\"\n",
        "\n",
        "print(text_original)\n",
        "print(\"\\nRemove punctuations..\")\n",
        "def remove_punctuation(text_original):\n",
        "    text_no_punctuation = text_original.translate(str.maketrans('','',string.punctuation))\n",
        "    return(text_no_punctuation)\n",
        "text_no_punctuation = remove_punctuation(text_original)\n",
        "print(text_no_punctuation)\n",
        "\n",
        "\n",
        "print(\"\\nRemove a single character word..\")\n",
        "def remove_single_character(text):\n",
        "    text_len_more_than1 = \"\"\n",
        "    for word in text.split():\n",
        "        if len(word) > 1:\n",
        "            text_len_more_than1 += \" \" + word\n",
        "    return(text_len_more_than1)\n",
        "text_len_more_than1 = remove_single_character(text_no_punctuation)\n",
        "print(text_len_more_than1)\n",
        "\n",
        "print(\"\\nRemove words with numeric values..\")\n",
        "def remove_numeric(text,printTF=False):\n",
        "    text_no_numeric = \"\"\n",
        "    for word in text.split():\n",
        "        isalpha = word.isalpha()\n",
        "        if printTF:\n",
        "            print(\"    {:10} : {:}\".format(word,isalpha))\n",
        "        if isalpha:\n",
        "            text_no_numeric += \" \" + word\n",
        "    return(text_no_numeric)\n",
        "text_no_numeric = remove_numeric(text_len_more_than1,printTF=True)\n",
        "print(text_no_numeric)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:23:51.801289Z",
          "iopub.execute_input": "2024-10-27T12:23:51.802141Z",
          "iopub.status.idle": "2024-10-27T12:23:51.813516Z",
          "shell.execute_reply.started": "2024-10-27T12:23:51.802097Z",
          "shell.execute_reply": "2024-10-27T12:23:51.812469Z"
        },
        "trusted": true,
        "id": "_axK0I4pqrt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_clean(text_original):\n",
        "    text = remove_punctuation(text_original)\n",
        "    text = remove_single_character(text)\n",
        "    text = remove_numeric(text)\n",
        "    return(text)\n",
        "\n",
        "\n",
        "for i, caption in enumerate(df_txt.caption.values):\n",
        "    newcaption = text_clean(caption)\n",
        "    df_txt[\"caption\"].iloc[i] = newcaption"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:24:24.353881Z",
          "iopub.execute_input": "2024-10-27T12:24:24.354351Z",
          "iopub.status.idle": "2024-10-27T12:24:41.028267Z",
          "shell.execute_reply.started": "2024-10-27T12:24:24.354307Z",
          "shell.execute_reply": "2024-10-27T12:24:41.02731Z"
        },
        "trusted": true,
        "id": "_7WfChLtqrt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the top 50 words that appear in the cleaned dataset\n",
        "topn = 50\n",
        "\n",
        "def plthist(dfsub, title=\"The top 50 most frequently appearing words\"):\n",
        "    plt.figure(figsize=(20,3))\n",
        "    plt.bar(dfsub.index,dfsub[\"count\"])\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.xticks(dfsub.index,dfsub[\"word\"],rotation=90,fontsize=20)\n",
        "    plt.title(title,fontsize=20)\n",
        "    plt.show()\n",
        "dfword = df_word(df_txt)\n",
        "plthist(dfword.iloc[:topn,:],\n",
        "        title=\"The top 50 most frequently appearing words\")\n",
        "plthist(dfword.iloc[-topn:,:],\n",
        "        title=\"The least 50 most frequently appearing words\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:25:05.77975Z",
          "iopub.execute_input": "2024-10-27T12:25:05.780363Z",
          "iopub.status.idle": "2024-10-27T12:25:07.367811Z",
          "shell.execute_reply.started": "2024-10-27T12:25:05.78031Z",
          "shell.execute_reply": "2024-10-27T12:25:07.366632Z"
        },
        "trusted": true,
        "id": "gUi41FDzqruA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding start and end sequence tokens for each captions\n",
        "from copy import copy\n",
        "def add_start_end_seq_token(captions):\n",
        "    caps = []\n",
        "    for txt in captions:\n",
        "        txt = 'startseq ' + txt + ' endseq'\n",
        "        caps.append(txt)\n",
        "    return(caps)\n",
        "df_txt0 = copy(df_txt)\n",
        "df_txt0[\"caption\"] = add_start_end_seq_token(df_txt[\"caption\"])\n",
        "df_txt0.head(5)\n",
        "del df_txt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:25:30.167395Z",
          "iopub.execute_input": "2024-10-27T12:25:30.168745Z",
          "iopub.status.idle": "2024-10-27T12:25:30.210675Z",
          "shell.execute_reply.started": "2024-10-27T12:25:30.168678Z",
          "shell.execute_reply": "2024-10-27T12:25:30.209341Z"
        },
        "trusted": true,
        "id": "YxdA5NqDqruA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_txt0[:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:25:43.695561Z",
          "iopub.execute_input": "2024-10-27T12:25:43.695984Z",
          "iopub.status.idle": "2024-10-27T12:25:43.709112Z",
          "shell.execute_reply.started": "2024-10-27T12:25:43.695946Z",
          "shell.execute_reply": "2024-10-27T12:25:43.707808Z"
        },
        "trusted": true,
        "id": "LAmaxIYLqruB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# Load the VGG16 model with pre-trained ImageNet weights\n",
        "modelvgg = VGG16(include_top=True, weights='imagenet')\n",
        "\n",
        "# Display the model summary\n",
        "modelvgg.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:26:13.335633Z",
          "iopub.execute_input": "2024-10-27T12:26:13.336112Z",
          "iopub.status.idle": "2024-10-27T12:26:18.73655Z",
          "shell.execute_reply.started": "2024-10-27T12:26:13.33604Z",
          "shell.execute_reply": "2024-10-27T12:26:18.735452Z"
        },
        "trusted": true,
        "id": "MFGc9rH0qruB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "\n",
        "# Load the VGG16 model with all top layers (fully connected layers included)\n",
        "modelvgg = VGG16(include_top=True, weights='imagenet')\n",
        "\n",
        "# Remove the last layer explicitly by setting the output layer to the layer before 'predictions'\n",
        "modelvgg = models.Model(inputs=modelvgg.input, outputs=modelvgg.get_layer(\"fc2\").output)\n",
        "\n",
        "# Display the model summary to confirm the parameter count\n",
        "modelvgg.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:27:56.157202Z",
          "iopub.execute_input": "2024-10-27T12:27:56.158254Z",
          "iopub.status.idle": "2024-10-27T12:27:58.506432Z",
          "shell.execute_reply.started": "2024-10-27T12:27:56.158205Z",
          "shell.execute_reply": "2024-10-27T12:27:58.505337Z"
        },
        "trusted": true,
        "id": "ivVtM5Z8qruB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "# Parameters and paths\n",
        "npix = 224  # VGG16 requires 224x224 pixel images\n",
        "target_size = (npix, npix)  # For load_img\n",
        "images = OrderedDict()\n",
        "\n",
        "# Initialize data array based on the number of images\n",
        "data = np.zeros((len(jpgs), npix, npix, 3))\n",
        "\n",
        "# Loop through each image and process\n",
        "for i, name in enumerate(jpgs):\n",
        "    # Load and preprocess the image\n",
        "    filename = os.path.join(dir_Flickr_jpg, name)\n",
        "    image = load_img(filename, target_size=target_size)\n",
        "    image = img_to_array(image)\n",
        "    nimage = preprocess_input(image)\n",
        "\n",
        "    # Predict features using VGG16\n",
        "    y_pred = modelvgg.predict(np.expand_dims(nimage, axis=0))  # Adding batch dimension\n",
        "    images[name] = y_pred.flatten()  # Flatten and save to the dictionary\n",
        "\n",
        "# Output summary\n",
        "print(\"Feature extraction complete for {} images.\".format(len(images)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:28:21.523915Z",
          "iopub.execute_input": "2024-10-27T12:28:21.524365Z"
        },
        "trusted": true,
        "id": "Gl9GMWyTqruB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "encoder = np.array(list(images.values()))\n",
        "#print(encoder)\n",
        "pca = PCA(n_components=2)\n",
        "#print(pca)\n",
        "y_pca = pca.fit_transform(encoder)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:47:09.788405Z",
          "iopub.execute_input": "2024-10-27T12:47:09.789468Z",
          "iopub.status.idle": "2024-10-27T12:47:11.786374Z",
          "shell.execute_reply.started": "2024-10-27T12:47:09.789414Z",
          "shell.execute_reply": "2024-10-27T12:47:11.784867Z"
        },
        "trusted": true,
        "id": "UMvHr9uaqruC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## some selected pictures that are creating clusters\n",
        "#these are just to display the related images from the dataset\n",
        "picked_pic = OrderedDict()\n",
        "picked_pic[\"red\"]     = [2720,4250,4983,5862,4079]\n",
        "picked_pic[\"green\"]   = [2070,3784,7545,4644, 4997]\n",
        "picked_pic[\"magenta\"] = [6320,3432,1348,7472, 1518]\n",
        "picked_pic[\"blue\"]    = [3901,2168,3465,5285,5328]\n",
        "picked_pic[\"yellow\"]  = [144,1172,4423,4780,4448]\n",
        "picked_pic[\"purple\"]  = [5087]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax.scatter(y_pca[:,0],y_pca[:,1],c=\"white\")\n",
        "\n",
        "for irow in range(y_pca.shape[0]):\n",
        "    ax.annotate(irow,y_pca[irow,:],color=\"black\",alpha=0.5) #annotate() is used to place text at the location of the point\n",
        "for color, irows in picked_pic.items():\n",
        "    for irow in irows:\n",
        "        ax.annotate(irow,y_pca[irow,:],color=color)\n",
        "ax.set_xlabel(\"pca embedding 1\",fontsize=30)\n",
        "ax.set_ylabel(\"pca embedding 2\",fontsize=30)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "## plot of images\n",
        "fig = plt.figure(figsize=(16,20))\n",
        "count = 1\n",
        "for color, irows in picked_pic.items():\n",
        "    for ivec in irows:\n",
        "        name = jpgs[ivec]\n",
        "        filename = dir_Flickr_jpg + '/' + name\n",
        "        image = load_img(filename, target_size=target_size)\n",
        "\n",
        "        ax = fig.add_subplot(len(picked_pic),5,count,\n",
        "                         xticks=[],yticks=[])\n",
        "        count += 1\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"{} ({})\".format(ivec,color))\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:48:05.387833Z",
          "iopub.execute_input": "2024-10-27T12:48:05.389395Z",
          "iopub.status.idle": "2024-10-27T12:48:51.061186Z",
          "shell.execute_reply.started": "2024-10-27T12:48:05.389342Z",
          "shell.execute_reply": "2024-10-27T12:48:51.059555Z"
        },
        "trusted": true,
        "id": "R3PCly1vqruC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging the images and the captions for training\n",
        "dimages, keepindex = [],[]\n",
        "# Creating a datframe where only first caption is taken for processing\n",
        "df_txt0 = df_txt0.loc[df_txt0[\"index\"].values == \"0\",: ]\n",
        "for i, fnm in enumerate(df_txt0.filename):\n",
        "    if fnm in images.keys():\n",
        "        dimages.append(images[fnm])\n",
        "        keepindex.append(i)\n",
        "\n",
        "#fnames are the names of the image files\n",
        "fnames = df_txt0[\"filename\"].iloc[keepindex].values\n",
        "#dcaptions are the captions of the images\n",
        "dcaptions = df_txt0[\"caption\"].iloc[keepindex].values\n",
        "#dimages are the actual features of the images\n",
        "dimages = np.array(dimages)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:50:07.027208Z",
          "iopub.execute_input": "2024-10-27T12:50:07.028113Z",
          "iopub.status.idle": "2024-10-27T12:50:07.107323Z",
          "shell.execute_reply.started": "2024-10-27T12:50:07.028037Z",
          "shell.execute_reply": "2024-10-27T12:50:07.106098Z"
        },
        "trusted": true,
        "id": "ZdftAj8eqruC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_txt0[:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:50:29.026187Z",
          "iopub.execute_input": "2024-10-27T12:50:29.026576Z",
          "iopub.status.idle": "2024-10-27T12:50:29.038946Z",
          "shell.execute_reply.started": "2024-10-27T12:50:29.026539Z",
          "shell.execute_reply": "2024-10-27T12:50:29.037788Z"
        },
        "trusted": true,
        "id": "nZZSwv7FqruC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizing the captions for further processing\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "## the maximum number of words in dictionary\n",
        "nb_words = 6000\n",
        "tokenizer = Tokenizer(nb_words=nb_words)\n",
        "tokenizer.fit_on_texts(dcaptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"vocabulary size : {}\".format(vocab_size))\n",
        "dtexts = tokenizer.texts_to_sequences(dcaptions)\n",
        "print(dtexts[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:50:49.861581Z",
          "iopub.execute_input": "2024-10-27T12:50:49.86199Z",
          "iopub.status.idle": "2024-10-27T12:50:50.174392Z",
          "shell.execute_reply.started": "2024-10-27T12:50:49.861951Z",
          "shell.execute_reply": "2024-10-27T12:50:50.173282Z"
        },
        "trusted": true,
        "id": "ALZcit2NqruD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the training and test data\n",
        "prop_test, prop_val = 0.2, 0.2\n",
        "\n",
        "N = len(dtexts)\n",
        "Ntest, Nval = int(N*prop_test), int(N*prop_val)\n",
        "\n",
        "def split_test_val_train(dtexts,Ntest,Nval):\n",
        "    return(dtexts[:Ntest],\n",
        "           dtexts[Ntest:Ntest+Nval],\n",
        "           dtexts[Ntest+Nval:])\n",
        "\n",
        "dt_test,  dt_val, dt_train   = split_test_val_train(dtexts,Ntest,Nval)\n",
        "di_test,  di_val, di_train   = split_test_val_train(dimages,Ntest,Nval)\n",
        "fnm_test,fnm_val, fnm_train  = split_test_val_train(fnames,Ntest,Nval)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:51:09.431731Z",
          "iopub.execute_input": "2024-10-27T12:51:09.432214Z",
          "iopub.status.idle": "2024-10-27T12:51:09.440938Z",
          "shell.execute_reply.started": "2024-10-27T12:51:09.432169Z",
          "shell.execute_reply": "2024-10-27T12:51:09.439381Z"
        },
        "trusted": true,
        "id": "zE0bUPnjqruD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the max length of the caption\n",
        "maxlen = np.max([len(text) for text in dtexts])\n",
        "print(maxlen)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:51:20.546177Z",
          "iopub.execute_input": "2024-10-27T12:51:20.547401Z",
          "iopub.status.idle": "2024-10-27T12:51:20.556956Z",
          "shell.execute_reply.started": "2024-10-27T12:51:20.547327Z",
          "shell.execute_reply": "2024-10-27T12:51:20.555694Z"
        },
        "trusted": true,
        "id": "-7U3xeiTqruD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing the captions and images as per the required shape by the model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def preprocessing(dtexts,dimages):\n",
        "    N = len(dtexts)\n",
        "    print(\"# captions/images = {}\".format(N))\n",
        "\n",
        "    assert(N==len(dimages)) # using assert to make sure that length of images and captions are always similar\n",
        "    Xtext, Ximage, ytext = [],[],[]\n",
        "    for text,image in zip(dtexts,dimages):\n",
        "        # zip() is used to create a tuple of iteratable items\n",
        "        for i in range(1,len(text)):\n",
        "            in_text, out_text = text[:i], text[i]\n",
        "            in_text = pad_sequences([in_text],maxlen=maxlen).flatten()# using pad sequence to make the length of all captions equal\n",
        "            out_text = to_categorical(out_text,num_classes = vocab_size) # using to_categorical to\n",
        "\n",
        "\n",
        "            Xtext.append(in_text)\n",
        "            Ximage.append(image)\n",
        "            ytext.append(out_text)\n",
        "\n",
        "    Xtext  = np.array(Xtext)\n",
        "    Ximage = np.array(Ximage)\n",
        "    ytext  = np.array(ytext)\n",
        "    print(\" {} {} {}\".format(Xtext.shape,Ximage.shape,ytext.shape))\n",
        "    return(Xtext,Ximage,ytext)\n",
        "\n",
        "\n",
        "Xtext_train, Ximage_train, ytext_train = preprocessing(dt_train,di_train)\n",
        "Xtext_val,   Ximage_val,   ytext_val   = preprocessing(dt_val,di_val)\n",
        "# pre-processing is not necessary for testing data\n",
        "#Xtext_test,  Ximage_test,  ytext_test  = preprocessing(dt_test,di_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:51:46.710028Z",
          "iopub.execute_input": "2024-10-27T12:51:46.711174Z",
          "iopub.status.idle": "2024-10-27T12:51:53.057102Z",
          "shell.execute_reply.started": "2024-10-27T12:51:46.711123Z",
          "shell.execute_reply": "2024-10-27T12:51:53.055909Z"
        },
        "trusted": true,
        "id": "d6sQStm8qruD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the LSTM model\n",
        "from tensorflow.keras import layers, models  # Updated import\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, LSTM, Embedding, Dense\n",
        "\n",
        "print(vocab_size)\n",
        "\n",
        "# Image feature\n",
        "dim_embedding = 64\n",
        "input_image = layers.Input(shape=(Ximage_train.shape[1],))  # Shape of your image features\n",
        "fimage = layers.Dense(256, activation='relu', name=\"ImageFeature\")(input_image)\n",
        "\n",
        "# Sequence model for captions\n",
        "input_txt = layers.Input(shape=(maxlen,))  # Length of your captions\n",
        "ftxt = layers.Embedding(vocab_size, dim_embedding, mask_zero=True)(input_txt)\n",
        "# Sequence model for captions with cuDNN disabled\n",
        "ftxt = layers.LSTM(256, name=\"CaptionFeature\", return_sequences=True, use_bias=False)(ftxt)\n",
        "se2 = Dropout(0.04)(ftxt)\n",
        "ftxt = layers.LSTM(256, name=\"CaptionFeature2\", use_bias=False)(se2)  # Also disable cuDNN here\n",
        "# Combined model for decoder\n",
        "decoder = layers.add([ftxt, fimage])\n",
        "decoder = Dense(256, activation='relu')(decoder)\n",
        "output = Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "# Build and compile the model\n",
        "model = models.Model(inputs=[input_image, input_txt], outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Display the model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:52:19.438915Z",
          "iopub.execute_input": "2024-10-27T12:52:19.439948Z",
          "iopub.status.idle": "2024-10-27T12:52:19.8498Z",
          "shell.execute_reply.started": "2024-10-27T12:52:19.439899Z",
          "shell.execute_reply": "2024-10-27T12:52:19.848673Z"
        },
        "trusted": true,
        "id": "nTxLCBr_qruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the LSTM model\n",
        "# fit model\n",
        "from time import time\n",
        "from keras.callbacks import TensorBoard\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "#start = time.time()\n",
        "hist = model.fit([Ximage_train, Xtext_train], ytext_train,\n",
        "                  epochs=6, verbose=2,\n",
        "                  batch_size=32,\n",
        "                  validation_data=([Ximage_val, Xtext_val], ytext_val),callbacks=[tensorboard])\n",
        "#end = time.time()\n",
        "#print(\"TIME TOOK {:3.2f}MIN\".format((end - start )/60))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:52:47.502773Z",
          "iopub.execute_input": "2024-10-27T12:52:47.503369Z",
          "iopub.status.idle": "2024-10-27T12:55:29.118221Z",
          "shell.execute_reply.started": "2024-10-27T12:52:47.503321Z",
          "shell.execute_reply": "2024-10-27T12:55:29.117141Z"
        },
        "trusted": true,
        "id": "rz-MtnmWqruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in [\"loss\",\"val_loss\"]:\n",
        "    plt.plot(hist.history[label],label=label)\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:58:16.778858Z",
          "iopub.execute_input": "2024-10-27T12:58:16.779504Z",
          "iopub.status.idle": "2024-10-27T12:58:17.097521Z",
          "shell.execute_reply.started": "2024-10-27T12:58:16.779443Z",
          "shell.execute_reply": "2024-10-27T12:58:17.09634Z"
        },
        "trusted": true,
        "id": "LtHYYlvbqruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating captions on a small set of images\n",
        "\n",
        "index_word = dict([(index,word) for word, index in tokenizer.word_index.items()])\n",
        "def predict_caption(image):\n",
        "    '''\n",
        "    image.shape = (1,4462)\n",
        "    '''\n",
        "\n",
        "    in_text = 'startseq'\n",
        "\n",
        "    for iword in range(maxlen):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence],maxlen)\n",
        "        yhat = model.predict([image,sequence],verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        newword = index_word[yhat]\n",
        "        in_text += \" \" + newword\n",
        "        if newword == \"endseq\":\n",
        "            break\n",
        "    return(in_text)\n",
        "\n",
        "\n",
        "\n",
        "npic = 5\n",
        "npix = 224\n",
        "target_size = (npix,npix,3)\n",
        "\n",
        "count = 1\n",
        "fig = plt.figure(figsize=(10,20))\n",
        "for jpgfnm, image_feature in zip(fnm_test[8:13],di_test[8:13]):\n",
        "    ## images\n",
        "    filename = dir_Flickr_jpg + '/' + jpgfnm\n",
        "    image_load = load_img(filename, target_size=target_size)\n",
        "    ax = fig.add_subplot(npic,2,count,xticks=[],yticks=[])\n",
        "    ax.imshow(image_load)\n",
        "    count += 1\n",
        "\n",
        "    ## captions\n",
        "    caption = predict_caption(image_feature.reshape(1,len(image_feature)))\n",
        "    ax = fig.add_subplot(npic,2,count)\n",
        "    plt.axis('off')\n",
        "    ax.plot()\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,1)\n",
        "    ax.text(0,0.5,caption,fontsize=20)\n",
        "    count += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T12:59:11.066746Z",
          "iopub.execute_input": "2024-10-27T12:59:11.067863Z",
          "iopub.status.idle": "2024-10-27T12:59:16.289906Z",
          "shell.execute_reply.started": "2024-10-27T12:59:11.067813Z",
          "shell.execute_reply": "2024-10-27T12:59:16.28863Z"
        },
        "trusted": true,
        "id": "gQw0SlpBqruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the model performance\n",
        "hypothesis = \"I like dog\"\n",
        "hypothesis = hypothesis.split()\n",
        "reference  = \"I do like dog\"\n",
        "references = [reference.split()] ## references must be a list containing list."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:00:23.051598Z",
          "iopub.execute_input": "2024-10-27T13:00:23.052683Z",
          "iopub.status.idle": "2024-10-27T13:00:23.057391Z",
          "shell.execute_reply.started": "2024-10-27T13:00:23.052626Z",
          "shell.execute_reply": "2024-10-27T13:00:23.056369Z"
        },
        "trusted": true,
        "id": "_2bM2h3fqruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "print(\"BLEU={:4.3f}\".format(sentence_bleu(references,hypothesis)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:00:27.624491Z",
          "iopub.execute_input": "2024-10-27T13:00:27.624932Z",
          "iopub.status.idle": "2024-10-27T13:00:28.099895Z",
          "shell.execute_reply.started": "2024-10-27T13:00:27.624891Z",
          "shell.execute_reply": "2024-10-27T13:00:28.098694Z"
        },
        "trusted": true,
        "id": "QRcaF9hyqruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis2 = \"I love dog!\".split()\n",
        "print(\"BLEU={:4.3f}\".format(sentence_bleu(references,  hypothesis2)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:01:00.463536Z",
          "iopub.execute_input": "2024-10-27T13:01:00.464338Z",
          "iopub.status.idle": "2024-10-27T13:01:00.470067Z",
          "shell.execute_reply.started": "2024-10-27T13:01:00.46429Z",
          "shell.execute_reply": "2024-10-27T13:01:00.468992Z"
        },
        "trusted": true,
        "id": "QwtMiu8FqruE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating captions for the whole test data and finding BLEU score\n",
        "index_word = dict([(index,word) for word, index in tokenizer.word_index.items()])\n",
        "\n",
        "\n",
        "nkeep = 5\n",
        "pred_good, pred_bad, bleus = [], [], []\n",
        "count = 0\n",
        "for jpgfnm, image_feature, tokenized_text in zip(fnm_test,di_test,dt_test):\n",
        "    count += 1\n",
        "    if count % 200 == 0:\n",
        "        print(\"  {:4.2f}% is done..\".format(100*count/float(len(fnm_test))))\n",
        "\n",
        "    caption_true = [ index_word[i] for i in tokenized_text ]\n",
        "    caption_true = caption_true[1:-1] ## remove startreg, and endreg\n",
        "    ## captions\n",
        "    caption = predict_caption(image_feature.reshape(1,len(image_feature)))\n",
        "    caption = caption.split()\n",
        "    caption = caption[1:-1]## remove startreg, and endreg\n",
        "\n",
        "    bleu = sentence_bleu([caption_true],caption)\n",
        "    bleus.append(bleu)\n",
        "    if bleu > 0.7 and len(pred_good) < nkeep:\n",
        "        pred_good.append((bleu,jpgfnm,caption_true,caption))\n",
        "    elif bleu < 0.3 and len(pred_bad) < nkeep:\n",
        "        pred_bad.append((bleu,jpgfnm,caption_true,caption))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:01:11.909002Z",
          "iopub.execute_input": "2024-10-27T13:01:11.909494Z",
          "iopub.status.idle": "2024-10-27T13:22:04.22136Z",
          "shell.execute_reply.started": "2024-10-27T13:01:11.909453Z",
          "shell.execute_reply": "2024-10-27T13:22:04.219984Z"
        },
        "trusted": true,
        "id": "yMUtw11DqruF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Assuming index_word, fnm_test, di_test, and dt_test are defined\n",
        "index_word = dict([(index, word) for word, index in tokenizer.word_index.items()])\n",
        "\n",
        "nkeep = 5\n",
        "pred_good, pred_bad, bleus = [], [], []\n",
        "count = 0\n",
        "\n",
        "for jpgfnm, image_feature, tokenized_text in zip(fnm_test, di_test, dt_test):\n",
        "    count += 1\n",
        "    if count % 200 == 0:\n",
        "        print(\"  {:4.2f}% is done..\".format(100 * count / float(len(fnm_test))))\n",
        "\n",
        "    caption_true = [index_word[i] for i in tokenized_text]\n",
        "    caption_true = caption_true[1:-1]  # remove startreg, and endreg\n",
        "\n",
        "    # Generate predicted caption\n",
        "    caption = predict_caption(image_feature.reshape(1, len(image_feature)))\n",
        "    caption = caption.split()\n",
        "    caption = caption[1:-1]  # remove startreg, and endreg\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu = sentence_bleu([caption_true], caption)\n",
        "    bleus.append(bleu)\n",
        "\n",
        "    # Keep track of good and bad predictions\n",
        "    if bleu > 0.7 and len(pred_good) < nkeep:\n",
        "        pred_good.append((bleu, jpgfnm, caption_true, caption))\n",
        "    elif bleu < 0.3 and len(pred_bad) < nkeep:\n",
        "        pred_bad.append((bleu, jpgfnm, caption_true, caption))\n",
        "\n",
        "# Print the mean BLEU score\n",
        "mean_bleu = np.mean(bleus)\n",
        "print(\"Mean BLEU {:4.3f}\".format(mean_bleu))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:25:25.707466Z",
          "iopub.execute_input": "2024-10-27T13:25:25.707959Z",
          "iopub.status.idle": "2024-10-27T13:46:28.785774Z",
          "shell.execute_reply.started": "2024-10-27T13:25:25.707913Z",
          "shell.execute_reply": "2024-10-27T13:46:28.784599Z"
        },
        "trusted": true,
        "id": "TygObMgWqruF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean BLEU {:4.3f}\".format(np.mean(bleus)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:48:01.86865Z",
          "iopub.execute_input": "2024-10-27T13:48:01.869697Z",
          "iopub.status.idle": "2024-10-27T13:48:01.876284Z",
          "shell.execute_reply.started": "2024-10-27T13:48:01.869647Z",
          "shell.execute_reply": "2024-10-27T13:48:01.875074Z"
        },
        "trusted": true,
        "id": "71iqyrmkqruF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Good and bad captions examples from the model\n",
        "def plot_images(pred_bad):\n",
        "    def create_str(caption_true):\n",
        "        strue = \"\"\n",
        "        for s in caption_true:\n",
        "            strue += \" \" + s\n",
        "        return(strue)\n",
        "    npix = 224\n",
        "    target_size = (npix,npix,3)\n",
        "    count = 1\n",
        "    fig = plt.figure(figsize=(10,20))\n",
        "    npic = len(pred_bad)\n",
        "    for pb in pred_bad:\n",
        "        bleu,jpgfnm,caption_true,caption = pb\n",
        "        ## images\n",
        "        filename = dir_Flickr_jpg + '/' + jpgfnm\n",
        "        image_load = load_img(filename, target_size=target_size)\n",
        "        ax = fig.add_subplot(npic,2,count,xticks=[],yticks=[])\n",
        "        ax.imshow(image_load)\n",
        "        count += 1\n",
        "\n",
        "        caption_true = create_str(caption_true)\n",
        "        caption = create_str(caption)\n",
        "\n",
        "        ax = fig.add_subplot(npic,2,count)\n",
        "        plt.axis('off')\n",
        "        ax.plot()\n",
        "        ax.set_xlim(0,1)\n",
        "        ax.set_ylim(0,1)\n",
        "        ax.text(0,0.7,\"true:\" + caption_true,fontsize=20)\n",
        "        ax.text(0,0.4,\"pred:\" + caption,fontsize=20)\n",
        "        ax.text(0,0.1,\"BLEU: {}\".format(bleu),fontsize=20)\n",
        "        count += 1\n",
        "    plt.show()\n",
        "\n",
        "print(\"Bad Caption\")\n",
        "plot_images(pred_bad)\n",
        "print(\"Good Caption\")\n",
        "plot_images(pred_good)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-27T13:48:47.680692Z",
          "iopub.execute_input": "2024-10-27T13:48:47.681165Z",
          "iopub.status.idle": "2024-10-27T13:48:49.56085Z",
          "shell.execute_reply.started": "2024-10-27T13:48:47.681123Z",
          "shell.execute_reply": "2024-10-27T13:48:49.559875Z"
        },
        "trusted": true,
        "id": "PUuzdo_JqruF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}